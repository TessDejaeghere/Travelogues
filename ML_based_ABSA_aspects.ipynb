{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/tess/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.data import Sentence\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"outputs/gold_aspects_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>words</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>labels_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>''</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CHAPTER</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>III</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>THE</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CUMÆAN</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>SIBYL</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>part</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>monotonous</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>coast-line</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>extends</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>into</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>considerably</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>beyond</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>rest</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>at</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>Carmel</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>B-aspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>'' CHAPTER III THE CUMÆAN SIBYL A part of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>''</td>\n",
       "      <td>'' This , and `` May God forgive the sins of y...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>This</td>\n",
       "      <td>'' This , and `` May God forgive the sins of y...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>'' This , and `` May God forgive the sins of y...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>'' This , and `` May God forgive the sins of y...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>'' This , and `` May God forgive the sins of y...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0          words  \\\n",
       "0            0             ''   \n",
       "1            0        CHAPTER   \n",
       "2            0            III   \n",
       "3            0            THE   \n",
       "4            0         CUMÆAN   \n",
       "5            0          SIBYL   \n",
       "6            0              A   \n",
       "7            0           part   \n",
       "8            0             of   \n",
       "9            0            the   \n",
       "10           0     monotonous   \n",
       "11           0     coast-line   \n",
       "12           0             of   \n",
       "13           0      Palestine   \n",
       "14           0        extends   \n",
       "15           0           into   \n",
       "16           0            the   \n",
       "17           0  Mediterranean   \n",
       "18           0   considerably   \n",
       "19           0         beyond   \n",
       "20           0            the   \n",
       "21           0           rest   \n",
       "22           0             at   \n",
       "23           0         Carmel   \n",
       "24           0              .   \n",
       "25           1             ''   \n",
       "26           1           This   \n",
       "27           1              ,   \n",
       "28           1            and   \n",
       "29           1             ``   \n",
       "\n",
       "                                             sentence  sent_id  labels_y  \n",
       "0   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "1   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "2   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "3   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "4   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "5   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "6   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "7   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "8   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "9   '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "10  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "11  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "12  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "13  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "14  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "15  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "16  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "17  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  I-aspect  \n",
       "18  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "19  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "20  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "21  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "22  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "23  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0  B-aspect  \n",
       "24  '' CHAPTER III THE CUMÆAN SIBYL A part of the ...        0         O  \n",
       "25  '' This , and `` May God forgive the sins of y...        1         O  \n",
       "26  '' This , and `` May God forgive the sins of y...        1         O  \n",
       "27  '' This , and `` May God forgive the sins of y...        1         O  \n",
       "28  '' This , and `` May God forgive the sins of y...        1         O  \n",
       "29  '' This , and `` May God forgive the sins of y...        1         O  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=[\"Caption\", \"Filename\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Aspect\": \"text\", \"labels_y\": \"bio\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 5 train-test split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits= 5, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for split in kf.split(df):\n",
    "    splits.append(split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(filename, sents_df):\n",
    "    with open(f\"/home/tess/experiments/train_test_splits/{filename}.txt\", \"w\") as f:\n",
    "        for el in sents_df: #for every sentence\n",
    "            for text, label in zip(el[1][\"text\"], el[1][\"bio\"]):\n",
    "                print(\"{}\\t{}\".format(text, label), file=f)\n",
    "            print(\"\\n\", file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, split in enumerate(kf.split(df)):\n",
    "    num += 1\n",
    "    \n",
    "    train = df.iloc[split[0]]\n",
    "    train_filename = \"train_\" + str(num) #make filename for train split\n",
    "\n",
    "    train_sentences = train.groupby(\"Filename\")\n",
    "    to_file(train_filename, train_sentences)\n",
    "    \n",
    "    test = df.iloc[split[1]]\n",
    "    test_filename = \"test_\" + str(num)\n",
    "    \n",
    "    test_sentences = test.groupby(\"Filename\")\n",
    "    to_file(test_filename, test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train sequence classifier \n",
    "* BERT\n",
    "* MACBERTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/tess/experiments/train_test_splits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {0: \"text\", 1: \"bio\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:13:05,857 Reading data from /home/tess/experiments/train_test_splits\n",
      "2023-12-08 15:13:05,859 Train: /home/tess/experiments/train_test_splits/train_5.txt\n",
      "2023-12-08 15:13:05,860 Dev: None\n",
      "2023-12-08 15:13:05,861 Test: /home/tess/experiments/train_test_splits/test_5.txt\n",
      "2023-12-08 15:13:07,564 No dev split found. Using 0% (i.e. 174 samples) of the train split as dev data\n"
     ]
    }
   ],
   "source": [
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train_5.txt',\n",
    "                              test_file='test_5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train) #sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:13:08,940 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1565it [00:00, 22372.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:13:09,019 Dictionary created for label 'bio' with 1 values: aspect (seen 5565 times)\n",
      "Dictionary with 1 tags: aspect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:13:12,488 SequenceTagger predicts: Dictionary with 5 tags: O, S-aspect, B-aspect, E-aspect, I-aspect\n",
      "2023-12-08 15:13:12,496 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,498 Model: \"SequenceTagger(\n",
      "  (embeddings): TransformerWordEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30001, 768)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (linear): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2023-12-08 15:13:12,498 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,499 Corpus: 1565 train + 174 dev + 441 test sentences\n",
      "2023-12-08 15:13:12,500 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,501 Train:  1565 sentences\n",
      "2023-12-08 15:13:12,501         (train_with_dev=False, train_with_test=False)\n",
      "2023-12-08 15:13:12,502 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,502 Training Params:\n",
      "2023-12-08 15:13:12,503  - learning_rate: \"5e-06\" \n",
      "2023-12-08 15:13:12,504  - mini_batch_size: \"4\"\n",
      "2023-12-08 15:13:12,505  - max_epochs: \"10\"\n",
      "2023-12-08 15:13:12,505  - shuffle: \"True\"\n",
      "2023-12-08 15:13:12,506 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,508 Plugins:\n",
      "2023-12-08 15:13:12,509  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2023-12-08 15:13:12,509 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,510 Final evaluation on model after last epoch (final-model.pt)\n",
      "2023-12-08 15:13:12,510  - metric: \"('micro avg', 'f1-score')\"\n",
      "2023-12-08 15:13:12,511 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,512 Computation:\n",
      "2023-12-08 15:13:12,513  - compute on device: cuda:0\n",
      "2023-12-08 15:13:12,513  - embedding storage: none\n",
      "2023-12-08 15:13:12,514 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,514 Model training base path: \"resources/taggers/sota-ner-flert\"\n",
      "2023-12-08 15:13:12,516 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:12,516 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:13:19,738 epoch 1 - iter 39/392 - loss 2.08484933 - time (sec): 7.22 - samples/sec: 712.84 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:13:26,842 epoch 1 - iter 78/392 - loss 2.07834598 - time (sec): 14.32 - samples/sec: 724.99 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:13:33,841 epoch 1 - iter 117/392 - loss 1.95778906 - time (sec): 21.32 - samples/sec: 771.75 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:13:40,802 epoch 1 - iter 156/392 - loss 1.76528586 - time (sec): 28.28 - samples/sec: 793.94 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:13:47,805 epoch 1 - iter 195/392 - loss 1.63719918 - time (sec): 35.28 - samples/sec: 775.86 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:13:54,754 epoch 1 - iter 234/392 - loss 1.48484267 - time (sec): 42.23 - samples/sec: 773.13 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:14:01,920 epoch 1 - iter 273/392 - loss 1.34481284 - time (sec): 49.40 - samples/sec: 779.54 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:14:09,174 epoch 1 - iter 312/392 - loss 1.24988110 - time (sec): 56.65 - samples/sec: 782.43 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:14:16,455 epoch 1 - iter 351/392 - loss 1.17531029 - time (sec): 63.93 - samples/sec: 780.75 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:14:23,560 epoch 1 - iter 390/392 - loss 1.11812039 - time (sec): 71.04 - samples/sec: 777.31 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:14:23,790 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:14:23,792 EPOCH 1 done: loss 1.1160 - lr: 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:14:25,318 DEV : loss 0.42506787180900574 - f1-score (micro avg)  0.4\n",
      "2023-12-08 15:14:25,329 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:14:32,608 epoch 2 - iter 39/392 - loss 0.52966440 - time (sec): 7.28 - samples/sec: 783.44 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:14:39,620 epoch 2 - iter 78/392 - loss 0.50749951 - time (sec): 14.29 - samples/sec: 759.80 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:14:46,677 epoch 2 - iter 117/392 - loss 0.51507718 - time (sec): 21.34 - samples/sec: 762.53 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:14:53,865 epoch 2 - iter 156/392 - loss 0.52085682 - time (sec): 28.53 - samples/sec: 769.57 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:01,019 epoch 2 - iter 195/392 - loss 0.52403391 - time (sec): 35.69 - samples/sec: 762.77 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:08,121 epoch 2 - iter 234/392 - loss 0.52181147 - time (sec): 42.79 - samples/sec: 760.76 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:15,165 epoch 2 - iter 273/392 - loss 0.51955783 - time (sec): 49.83 - samples/sec: 770.03 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:22,410 epoch 2 - iter 312/392 - loss 0.51620946 - time (sec): 57.08 - samples/sec: 772.28 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:29,677 epoch 2 - iter 351/392 - loss 0.50550085 - time (sec): 64.34 - samples/sec: 771.73 - lr: 0.000005 - momentum: 0.000000\n",
      "2023-12-08 15:15:36,789 epoch 2 - iter 390/392 - loss 0.50105028 - time (sec): 71.46 - samples/sec: 771.36 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:15:37,025 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:15:37,026 EPOCH 2 done: loss 0.5013 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:15:38,970 DEV : loss 0.40169888734817505 - f1-score (micro avg)  0.5084\n",
      "2023-12-08 15:15:38,980 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:15:46,028 epoch 3 - iter 39/392 - loss 0.44310533 - time (sec): 7.05 - samples/sec: 823.75 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:15:53,336 epoch 3 - iter 78/392 - loss 0.45103962 - time (sec): 14.35 - samples/sec: 767.99 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:00,614 epoch 3 - iter 117/392 - loss 0.46333794 - time (sec): 21.63 - samples/sec: 749.11 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:07,819 epoch 3 - iter 156/392 - loss 0.43512092 - time (sec): 28.84 - samples/sec: 753.27 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:15,073 epoch 3 - iter 195/392 - loss 0.43604739 - time (sec): 36.09 - samples/sec: 761.75 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:22,307 epoch 3 - iter 234/392 - loss 0.44692189 - time (sec): 43.32 - samples/sec: 773.28 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:29,167 epoch 3 - iter 273/392 - loss 0.43573674 - time (sec): 50.19 - samples/sec: 769.41 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:36,121 epoch 3 - iter 312/392 - loss 0.43610800 - time (sec): 57.14 - samples/sec: 772.97 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:43,252 epoch 3 - iter 351/392 - loss 0.43487343 - time (sec): 64.27 - samples/sec: 772.95 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:50,268 epoch 3 - iter 390/392 - loss 0.43232480 - time (sec): 71.29 - samples/sec: 775.02 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:16:50,513 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:16:50,514 EPOCH 3 done: loss 0.4320 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:16:52,652 DEV : loss 0.3584291338920593 - f1-score (micro avg)  0.5891\n",
      "2023-12-08 15:16:52,666 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:16:59,990 epoch 4 - iter 39/392 - loss 0.35856894 - time (sec): 7.32 - samples/sec: 744.91 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:07,291 epoch 4 - iter 78/392 - loss 0.36588293 - time (sec): 14.62 - samples/sec: 744.90 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:14,525 epoch 4 - iter 117/392 - loss 0.36684325 - time (sec): 21.86 - samples/sec: 755.42 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:21,649 epoch 4 - iter 156/392 - loss 0.37224226 - time (sec): 28.98 - samples/sec: 755.17 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:28,712 epoch 4 - iter 195/392 - loss 0.39283967 - time (sec): 36.04 - samples/sec: 758.27 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:35,706 epoch 4 - iter 234/392 - loss 0.39920439 - time (sec): 43.04 - samples/sec: 767.27 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:42,584 epoch 4 - iter 273/392 - loss 0.40691627 - time (sec): 49.91 - samples/sec: 780.29 - lr: 0.000004 - momentum: 0.000000\n",
      "2023-12-08 15:17:49,422 epoch 4 - iter 312/392 - loss 0.39630115 - time (sec): 56.75 - samples/sec: 779.99 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:17:56,372 epoch 4 - iter 351/392 - loss 0.39650073 - time (sec): 63.70 - samples/sec: 776.48 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:03,348 epoch 4 - iter 390/392 - loss 0.39886511 - time (sec): 70.68 - samples/sec: 781.56 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:03,578 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:18:03,579 EPOCH 4 done: loss 0.3987 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:18:05,515 DEV : loss 0.3526793420314789 - f1-score (micro avg)  0.5663\n",
      "2023-12-08 15:18:05,525 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:18:12,518 epoch 5 - iter 39/392 - loss 0.32597997 - time (sec): 6.99 - samples/sec: 750.55 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:19,511 epoch 5 - iter 78/392 - loss 0.34093989 - time (sec): 13.98 - samples/sec: 763.71 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:26,483 epoch 5 - iter 117/392 - loss 0.39150981 - time (sec): 20.96 - samples/sec: 773.93 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:33,437 epoch 5 - iter 156/392 - loss 0.37178075 - time (sec): 27.91 - samples/sec: 785.61 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:40,339 epoch 5 - iter 195/392 - loss 0.37053194 - time (sec): 34.81 - samples/sec: 812.83 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:47,227 epoch 5 - iter 234/392 - loss 0.36432367 - time (sec): 41.70 - samples/sec: 809.35 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:18:54,190 epoch 5 - iter 273/392 - loss 0.35983767 - time (sec): 48.66 - samples/sec: 798.80 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:01,250 epoch 5 - iter 312/392 - loss 0.36872174 - time (sec): 55.72 - samples/sec: 794.59 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:08,458 epoch 5 - iter 351/392 - loss 0.36675627 - time (sec): 62.93 - samples/sec: 788.69 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:15,497 epoch 5 - iter 390/392 - loss 0.37174933 - time (sec): 69.97 - samples/sec: 788.80 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:15,736 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:19:15,737 EPOCH 5 done: loss 0.3723 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:19:18,409 DEV : loss 0.32897722721099854 - f1-score (micro avg)  0.6027\n",
      "2023-12-08 15:19:18,419 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:19:25,392 epoch 6 - iter 39/392 - loss 0.32966376 - time (sec): 6.97 - samples/sec: 832.64 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:32,547 epoch 6 - iter 78/392 - loss 0.36416378 - time (sec): 14.13 - samples/sec: 788.84 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:39,784 epoch 6 - iter 117/392 - loss 0.38000108 - time (sec): 21.36 - samples/sec: 785.24 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:47,347 epoch 6 - iter 156/392 - loss 0.36307655 - time (sec): 28.93 - samples/sec: 766.38 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:19:55,253 epoch 6 - iter 195/392 - loss 0.36309102 - time (sec): 36.83 - samples/sec: 747.08 - lr: 0.000003 - momentum: 0.000000\n",
      "2023-12-08 15:20:02,839 epoch 6 - iter 234/392 - loss 0.36412692 - time (sec): 44.42 - samples/sec: 742.71 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:10,331 epoch 6 - iter 273/392 - loss 0.36196950 - time (sec): 51.91 - samples/sec: 742.86 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:17,805 epoch 6 - iter 312/392 - loss 0.35490905 - time (sec): 59.38 - samples/sec: 737.63 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:25,331 epoch 6 - iter 351/392 - loss 0.35688343 - time (sec): 66.91 - samples/sec: 740.79 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:32,574 epoch 6 - iter 390/392 - loss 0.36138904 - time (sec): 74.15 - samples/sec: 744.17 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:32,808 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:20:32,809 EPOCH 6 done: loss 0.3611 - lr: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:20:34,727 DEV : loss 0.3244566321372986 - f1-score (micro avg)  0.6141\n",
      "2023-12-08 15:20:34,738 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:20:42,268 epoch 7 - iter 39/392 - loss 0.35041957 - time (sec): 7.53 - samples/sec: 752.15 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:50,096 epoch 7 - iter 78/392 - loss 0.35293475 - time (sec): 15.36 - samples/sec: 724.38 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:20:57,265 epoch 7 - iter 117/392 - loss 0.33603914 - time (sec): 22.52 - samples/sec: 738.14 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:04,634 epoch 7 - iter 156/392 - loss 0.33678257 - time (sec): 29.89 - samples/sec: 750.63 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:12,107 epoch 7 - iter 195/392 - loss 0.33540040 - time (sec): 37.37 - samples/sec: 741.52 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:19,553 epoch 7 - iter 234/392 - loss 0.33001350 - time (sec): 44.81 - samples/sec: 737.16 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:26,904 epoch 7 - iter 273/392 - loss 0.33537618 - time (sec): 52.16 - samples/sec: 737.63 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:34,417 epoch 7 - iter 312/392 - loss 0.33668821 - time (sec): 59.68 - samples/sec: 743.26 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:41,311 epoch 7 - iter 351/392 - loss 0.33598028 - time (sec): 66.57 - samples/sec: 748.16 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:49,117 epoch 7 - iter 390/392 - loss 0.33957561 - time (sec): 74.38 - samples/sec: 741.21 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:21:49,369 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:21:49,370 EPOCH 7 done: loss 0.3391 - lr: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:21:51,370 DEV : loss 0.32633787393569946 - f1-score (micro avg)  0.612\n",
      "2023-12-08 15:21:51,381 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:21:58,933 epoch 8 - iter 39/392 - loss 0.36503467 - time (sec): 7.55 - samples/sec: 684.79 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:22:06,501 epoch 8 - iter 78/392 - loss 0.33253061 - time (sec): 15.12 - samples/sec: 720.91 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:22:14,077 epoch 8 - iter 117/392 - loss 0.31622426 - time (sec): 22.69 - samples/sec: 739.02 - lr: 0.000002 - momentum: 0.000000\n",
      "2023-12-08 15:22:21,573 epoch 8 - iter 156/392 - loss 0.32177549 - time (sec): 30.19 - samples/sec: 728.09 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:22:29,116 epoch 8 - iter 195/392 - loss 0.32555810 - time (sec): 37.73 - samples/sec: 731.31 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:22:36,628 epoch 8 - iter 234/392 - loss 0.33366521 - time (sec): 45.24 - samples/sec: 728.18 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:22:43,765 epoch 8 - iter 273/392 - loss 0.33470553 - time (sec): 52.38 - samples/sec: 737.40 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:22:51,048 epoch 8 - iter 312/392 - loss 0.33885319 - time (sec): 59.66 - samples/sec: 734.77 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:22:58,563 epoch 8 - iter 351/392 - loss 0.33117702 - time (sec): 67.18 - samples/sec: 737.83 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:05,499 epoch 8 - iter 390/392 - loss 0.32941930 - time (sec): 74.12 - samples/sec: 744.67 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:05,740 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:23:05,741 EPOCH 8 done: loss 0.3293 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:23:07,830 DEV : loss 0.3286391794681549 - f1-score (micro avg)  0.6183\n",
      "2023-12-08 15:23:07,840 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:23:14,713 epoch 9 - iter 39/392 - loss 0.30917084 - time (sec): 6.87 - samples/sec: 766.99 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:22,161 epoch 9 - iter 78/392 - loss 0.28905659 - time (sec): 14.32 - samples/sec: 751.06 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:29,978 epoch 9 - iter 117/392 - loss 0.29830022 - time (sec): 22.13 - samples/sec: 747.67 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:37,417 epoch 9 - iter 156/392 - loss 0.30091799 - time (sec): 29.57 - samples/sec: 744.98 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:44,847 epoch 9 - iter 195/392 - loss 0.29783788 - time (sec): 37.00 - samples/sec: 737.14 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:52,156 epoch 9 - iter 234/392 - loss 0.31295937 - time (sec): 44.31 - samples/sec: 743.17 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:23:59,744 epoch 9 - iter 273/392 - loss 0.31267929 - time (sec): 51.90 - samples/sec: 735.91 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:24:07,070 epoch 9 - iter 312/392 - loss 0.31216752 - time (sec): 59.23 - samples/sec: 740.88 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:24:14,442 epoch 9 - iter 351/392 - loss 0.31457313 - time (sec): 66.60 - samples/sec: 741.98 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:24:21,438 epoch 9 - iter 390/392 - loss 0.31181893 - time (sec): 73.59 - samples/sec: 750.66 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:24:21,677 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:24:21,678 EPOCH 9 done: loss 0.3130 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:24:23,730 DEV : loss 0.3304169476032257 - f1-score (micro avg)  0.6187\n",
      "2023-12-08 15:24:23,742 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:24:31,458 epoch 10 - iter 39/392 - loss 0.30666172 - time (sec): 7.71 - samples/sec: 729.80 - lr: 0.000001 - momentum: 0.000000\n",
      "2023-12-08 15:24:39,397 epoch 10 - iter 78/392 - loss 0.28872055 - time (sec): 15.65 - samples/sec: 705.83 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:24:46,577 epoch 10 - iter 117/392 - loss 0.30685347 - time (sec): 22.83 - samples/sec: 708.73 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:24:54,219 epoch 10 - iter 156/392 - loss 0.30065594 - time (sec): 30.47 - samples/sec: 715.53 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:01,630 epoch 10 - iter 195/392 - loss 0.31475251 - time (sec): 37.88 - samples/sec: 716.65 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:09,209 epoch 10 - iter 234/392 - loss 0.32372924 - time (sec): 45.46 - samples/sec: 718.81 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:16,962 epoch 10 - iter 273/392 - loss 0.31782745 - time (sec): 53.22 - samples/sec: 722.38 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:24,581 epoch 10 - iter 312/392 - loss 0.31817502 - time (sec): 60.84 - samples/sec: 719.27 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:32,136 epoch 10 - iter 351/392 - loss 0.32087759 - time (sec): 68.39 - samples/sec: 723.24 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:39,580 epoch 10 - iter 390/392 - loss 0.31632380 - time (sec): 75.83 - samples/sec: 727.48 - lr: 0.000000 - momentum: 0.000000\n",
      "2023-12-08 15:25:39,830 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:25:39,831 EPOCH 10 done: loss 0.3159 - lr: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:25:42,231 DEV : loss 0.3353153169155121 - f1-score (micro avg)  0.6152\n",
      "2023-12-08 15:25:43,204 ----------------------------------------------------------------------------------------------------\n",
      "2023-12-08 15:25:43,208 Testing using last state of model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:25:47,480 \n",
      "Results:\n",
      "- F-score (micro) 0.6099\n",
      "- F-score (macro) 0.6099\n",
      "- Accuracy 0.4388\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      aspect     0.6442    0.5791    0.6099      1466\n",
      "\n",
      "   micro avg     0.6442    0.5791    0.6099      1466\n",
      "   macro avg     0.6442    0.5791    0.6099      1466\n",
      "weighted avg     0.6442    0.5791    0.6099      1466\n",
      "\n",
      "2023-12-08 15:25:47,482 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6099137931034482}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. what label do we want to predict?\n",
    "label_type = 'bio'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type, add_unk=False)\n",
    "print(label_dict)\n",
    "\n",
    "# 4. initialize fine-tuneable transformer embeddings WITH document context\n",
    "embeddings = TransformerWordEmbeddings(model='emanjavacas/MacBERTh',\n",
    "                                       layers=\"-1\", #ONLY USE THE LAST LAYER (embeddings)\n",
    "                                       subtoken_pooling=\"first\",\n",
    "                                       fine_tune=True, #adapt model to data\n",
    "                                       use_context=True, #document context is considered during the embedding process (surrounding words, ...)\n",
    "                                       )\n",
    "\n",
    "# 5. initialize bare-bones sequence tagger (no CRF, no RNN, no reprojection)\n",
    "# EMBEDDINGS ARE DIRECTLY USED without any linear projection\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type='bio',\n",
    "                        use_crf=False,\n",
    "                        use_rnn=False,\n",
    "                        reproject_embeddings=False,\n",
    "                        )\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. run fine-tuning\n",
    "trainer.fine_tune('resources/taggers/sota-ner-flert',\n",
    "                  learning_rate=5.0e-6,\n",
    "                  mini_batch_size=4,\n",
    "                  mini_batch_chunk_size=1,  # remove this parameter to speed up computation if you have a big GPU\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sentence\n",
    "sentence = Sentence('I saw a weeping willow while passing down the alleyway. The thorns of the roses reminded me of home, in Alabama.')\n",
    "\n",
    "# predict aspect tags\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[24]: \"I saw a weeping willow while passing down the alleyway. The thorns of the roses reminded me of home, in Alabama.\" → [\"willow\"/aspect, \"roses\"/aspect, \"Alabama\"/aspect]\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
